<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="3.6.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2017-12-18T15:34:48+00:00</updated><id>http://localhost:4000/</id><title type="html">Alex Tsaptsinos</title><subtitle>**Alex Tsaptsinos**, Stanford ICME MS Student Music, Machine Learning, Football
</subtitle><author><name>Alexandros Tsaptsinos</name><email>&lt;alextsap@stanford.edu&gt;</email></author><entry><title type="html">Genetic Algorithms at Shazam</title><link href="http://localhost:4000/2017/10/19/shazam/" rel="alternate" type="text/html" title="Genetic Algorithms at Shazam" /><published>2017-10-19T00:00:00+01:00</published><updated>2017-10-19T00:00:00+01:00</updated><id>http://localhost:4000/2017/10/19/shazam</id><content type="html" xml:base="http://localhost:4000/2017/10/19/shazam/">&lt;p&gt;I spent this last summer working at Shazam as part of their R&amp;amp;D team in Redwood City. I wrote a blog post detailing the project I worked on &lt;a href=&quot;https://blog.shazam.com/optimizing-the-shazam-backend-structure-via-genetic-algorithms-4ade88898972&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It was a great summer within an awesome team!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/shazam_logo.png&quot; alt=&quot;Shazam!&quot; /&gt;&lt;/p&gt;</content><author><name>author</name></author><summary type="html">I spent this last summer working at Shazam as part of their R&amp;amp;D team in Redwood City. I wrote a blog post detailing the project I worked on here.</summary></entry><entry><title type="html">Classifying Music Genres via Lyrics using a Hierarchical Attention Network</title><link href="http://localhost:4000/2017/06/21/lyricsHAN/" rel="alternate" type="text/html" title="Classifying Music Genres via Lyrics using a Hierarchical Attention Network" /><published>2017-06-21T00:00:00+01:00</published><updated>2017-06-21T00:00:00+01:00</updated><id>http://localhost:4000/2017/06/21/lyricsHAN</id><content type="html" xml:base="http://localhost:4000/2017/06/21/lyricsHAN/">&lt;p&gt;To begin the project I took inspiration from &lt;a href=&quot;http://www.aclweb.org/anthology/N16-1174&quot;&gt;the paper by Yang et al.&lt;/a&gt; using a Hierachical Attention Network (HAN) to classify documents. Similarly to documents, lyrics contain a hierachical structure: words go into lines, lines into sections (verse/chorus/…), and sections then form the whole song. Further, from the attention mechanism we can then extract and visualise where the network is applying its weights.&lt;/p&gt;

&lt;p&gt;Using intact lyrics the song can be split into layers. At each layer we apply a bidirectional recurrent neural network (RNN) to obtain hidden state representations. The attention mechanism is then applied to form a weighted sum of that layers hidden representations i.e. a weighted sum of the word hidden representation vectors forms the line vector. We have now passed to a higher layer and can repeat the process until we finally end up with a vector which summarizes the whole song, from which we can classify via a softmax activation.&lt;/p&gt;

&lt;p&gt;The structure of the network can be seen for the example song of ‘Happy Birthday’ below.
&lt;img src=&quot;/assets/img/lyricsHAN/network_image.pdf&quot; alt=&quot;HAN Architecture&quot; /&gt;
&lt;!--![HAN Architecture](/assets/img/lyricsHAN/network_image.pdf)--&gt;&lt;/p&gt;

&lt;p&gt;The HAN model was written using TensorFlow, with Keras as the top layer whenever possible. &lt;a href=&quot;https://richliao.github.io/supervised/classification/2016/12/26/textclassifier-HATN/&quot;&gt;This great blog post by Richard Liao&lt;/a&gt; really helped guide me, since I was just starting out with TensorFlow then.&lt;/p&gt;

&lt;p&gt;I was incredibly lucky to have been provided intact song lyrics from &lt;a href=&quot;http://www.lyricfind.com/&quot;&gt;LyricFind&lt;/a&gt;, without which this project would not have been possible. After pre-processing the lyrics and tokenizing them we were able to train the HAN and test its performance. The HAN was compared to several baseline model and performed well compared to previous research, although the LSTM outperformed in in the 20 genre case. Results can be seen here:
&lt;img src=&quot;/assets/img/lyricsHAN/results.png&quot; alt=&quot;HAN results&quot; /&gt;&lt;/p&gt;

&lt;p&gt;HN is the HAN network without the attention mechanism. HAN-L is the HAN model with layers at the word and line level. HAN-S is the HAN model with layers at the word and section level.&lt;/p&gt;

&lt;p&gt;As is evident, classifying solely by lyrics remains a hard task! It’s hard to compare to previous research, with varying number of genres used, varying genres in those lists, and no real standardisation of genres. However, we believe that these scores were some of the best reported!&lt;/p&gt;

&lt;p&gt;The benefit of using the attention mechanism is the abilitiy to now feed in lyrics and visualise where the netowrk is applying heavy weights. In other words, we can see which words, or lines, the network deems important to classifying the genre. Below are some examples where the network correctly predicts the genre.
&lt;img src=&quot;/assets/img/lyricsHAN/country_example.pdf&quot; alt=&quot;HAN results&quot; /&gt;
&lt;img src=&quot;/assets/img/lyricsHAN/rap_example.pdf&quot; alt=&quot;HAN results&quot; /&gt;
&lt;img src=&quot;/assets/img/lyricsHAN/rock_example.pdf&quot; alt=&quot;HAN results&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We can see heavy weights on classic country words ‘baby’, ‘driveway’, ‘ai’, etc. Similarly, for the hip-hop/rap song we see mispellings and lite-cuss words heavily weighted. When heavier cuss words are used the HAN similarly applied heavy weights. One interesting pattern in rock we noticed was the heavy weighting of second-person pronouns such as ‘you’ or ‘your’. This is contrasted by the weighting of first-person pronouns ‘me’, ‘mine’ in hip-hop/rap!&lt;/p&gt;

&lt;p&gt;Of course, the network didn’t get it right all the time. Below are some examples of the HAN incorrectly classifying the genre, although in each case you can see why it has done so.
&lt;img src=&quot;/assets/img/lyricsHAN/popwrong_country_example.pdf&quot; alt=&quot;HAN results&quot; /&gt;
&lt;img src=&quot;/assets/img/lyricsHAN/popwrong_example.pdf&quot; alt=&quot;HAN results&quot; /&gt;
&lt;img src=&quot;/assets/img/lyricsHAN/rapwrong_pop_example.pdf&quot; alt=&quot;HAN results&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Classification by lyrics alone is always going to be tricky, with vague genre boundaries and cover songs hardening matters. However, in combination with audio or symbolic data we believe the HAN could help boost genre classification accuracies.&lt;/p&gt;

&lt;p&gt;All the code is avalable &lt;a href=&quot;https://github.com/alexTsaptsinos/lyricsHAN&quot;&gt;here&lt;/a&gt;, although I apologise in advance for not being formatted very cleanly.&lt;/p&gt;

&lt;p&gt;For all the gory details you can read the full paper &lt;a href=&quot;https://alextsaptsinos.github.io/papers/lyricspaper.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Please get in touch if you have any questions!&lt;/p&gt;</content><author><name>author</name></author><summary type="html">To begin the project I took inspiration from the paper by Yang et al. using a Hierachical Attention Network (HAN) to classify documents. Similarly to documents, lyrics contain a hierachical structure: words go into lines, lines into sections (verse/chorus/…), and sections then form the whole song. Further, from the attention mechanism we can then extract and visualise where the network is applying its weights.</summary></entry></feed>